# PROVER-VERIFIER GAMES IMPROVE LEGIBILITY OF LLM OUTPUTS
Jan Hendrik Kirchner\* Yining Chen\*
Harri Edwards† Jan Leike† Nat McAleese Yuri Burda†
OpenAI

## D ADDITIONAL EVALUATIONS FOR THE GOODHARTING BASELINE
![](4e5abec2ae85a6a3a1366c722daceccd_img.jpg)
Figure S6 consists of two bar charts, (a) and (b), illustrating results related to the Goodharting baseline.
**Chart (a): Accuracy vs Round**
| Round | Accuracy |
|-------|----------|
| 0     | ~0.80    |
| 1     | ~0.81    |
| 2     | ~0.805   |
**Chart (b): Time to judgement (s) vs Round**
| Round | Incorrect (s) | Correct (s) |
|-------|---------------|-------------|
| 0     | ~51           | ~43         |
| 1     | ~46           | ~44         |
| 2     | ~44           | ~37         |
Supplementary Figure S6: **Test samples generated by provers at the end of three rounds of goodharting training do not have significant increase in human trainer accuracy across R0-2.** This experiment uses a verifier roughly  $10^{-3}$  of the prover size. This plot is from a potentially flawed campaign (see Appendix I).
![](85b10db535b22e64c7d37f362705ddbf_img.jpg)
Figure S7 displays two line charts comparing the number of RL steps until exploit versus round for two objectives (SRC and CGC) under two verifier sizes.
**(a) Verifier size  $10^{-3}$**
| Round | SRC (RL steps) | CGC (RL steps) |
|-------|----------------|----------------|
| 0     | ~1.6k          | ~3.2k          |
| 1     | ~2k            | ~2k            |
| 2     | ~4.2k          | ~4.2k          |
**(b) Verifier size  $3 \times 10^{-3}$**
| Round | SRC (RL steps) | CGC (RL steps) |
|-------|----------------|----------------|
| 0     | ~2k            | ~4k            |
| 1     | ~2.2k          | ~2.2k          |
| 2     | ~1.5k          | ~7.5k          |
| 3     | ~7.5k          | ~3k            |
Supplementary Figure S7: **Evaluations for iterative goodharting training.** Verifier has relative size  $10^{-3}$  (left) and  $3 \times 10^{-3}$  (right). Y-axis is the number of RL steps until the attacker reaches verifier score as high as the prover's and 95% incorrect. The attacker is trained using either the SRC or CGC reward.
![](4cec89a753c447a050c0171c274f2acb_img.jpg)
**Accuracy best of  $n$  vs. number of completions  $n$**
| number of completions $n$ | Round 0 | Round 1 | Round 2 | Round 3 |
|---------------------------|---------|---------|---------|---------|
| 0                         | 0.65    | 0.58    | 0.52    | 0.48    |
| 200                       | 0.58    | 0.50    | 0.43    | 0.34    |
| 400                       | 0.56    | 0.49    | 0.41    | 0.33    |
| 600                       | 0.56    | 0.50    | 0.39    | 0.32    |
Supplementary Figure S8: **Balanced best-of- $n$  for iterative goodharting training with verifier relative size  $3 \times 10^{-3}$ .** The solutions are current-round last-checkpoint prover samples balanced at 50% correct and 50% incorrect.
