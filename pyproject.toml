[project]
name = "ludic"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "aiohttp>=3.13.2",
    "openai>=2.7.1",
    "peft>=0.18.0",
    "rich>=14.2.0",
    "setuptools>=79.0.1",
    # torch/vllm: use UV_TORCH_BACKEND=cu128 on GPU systems (aarch64/x86)
    # See: https://docs.astral.sh/uv/guides/integration/pytorch/
    "torch>=2.8.0",
    "vllm>=0.11.0",
]

[project.optional-dependencies]
code-exec = [
    "docker>=7.1.0",
]

[build-system]
requires = ["uv_build>=0.9.5,<0.10.0"]
build-backend = "uv_build"

[dependency-groups]
dev = [
    "mypy>=1.18.2",
    "pytest>=8.4.2",
    "pytest-asyncio>=1.2.0",
    "ruff>=0.14.5",
]
pipelinerl = [
    "redis>=7.1.0",
]
examples = [
    "datasets",
    "math-verify",
]

[tool.pytest.ini_options]
markers = [
    "integration: marks tests as integration tests",
    "gpu: marks tests as needing a GPU",
    "report: marks tests that primarily emit diagnostic reports rather than asserting strict correctness",
]
testpaths = ["tests"]

# =============================================================================
# uv Configuration for PyTorch CUDA
# =============================================================================
# PyTorch publishes different wheels for CPU/CUDA on separate indexes.
# By default, uv uses CPU wheels for aarch64 (ARM) systems.
#
# IMPORTANT: --torch-backend only works with 'uv pip', NOT 'uv sync'!
#
# For GPU systems (Isambard-AI GH200, etc.):
#   uv pip install torch torchvision --torch-backend=cu128
#   uv pip install vllm --torch-backend=cu128
#   uv run --no-sync python ...   # --no-sync prevents reverting to CPU
#
# For CPU systems (local dev):
#   uv sync   # Uses default CPU wheels
#
# See: https://docs.astral.sh/uv/guides/integration/pytorch/
# See: https://docs.isambard.ac.uk/user-documentation/applications/ML-packages/
# =============================================================================

[tool.uv]

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
